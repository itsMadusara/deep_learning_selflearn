{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "Rank 0 tensors are Scalers\\\n",
    "Rank 1 tensors are arrays\\\n",
    "Rank 3 tensors are Matrices\\\n",
    "Tensors contains three key attributes : Axes, Shape, dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axes (0, 1, 2, 3)\n",
      "shape ((), (3,), (3, 3), (3, 3, 3))\n",
      "datatypes (dtype('int32'), dtype('int32'), dtype('int32'), dtype('int32'))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rank0 = np.array(12)\n",
    "rank1 = np.array([1, 2, 3])\n",
    "rank2 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "rank3 = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "                  [[10, 11, 12], [13, 14, 15], [16, 17, 18]],\n",
    "                  [[19, 20, 21], [22, 23, 24], [25, 26, 27]]])\n",
    "axes = rank0.ndim, rank1.ndim, rank2.ndim, rank3.ndim\n",
    "print(\"axes\", axes)\n",
    "shape = rank0.shape, rank1.shape, rank2.shape, rank3.shape\n",
    "print(\"shape\", shape)\n",
    "datatypes = rank0.dtype, rank1.dtype, rank2.dtype, rank3.dtype\n",
    "print(\"datatypes\", datatypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the available tensor attributes using MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Slicing** is the process of selecting elements in a tensor.\\\n",
    "**First Axis** of the data tensor is called samples axis.\\\n",
    "When considering batches the first axis is called **Batch Axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "first_sclice = train_images[10:100, : , :]\n",
    "print(first_sclice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Tensors** will always fall into one of the following categories.\\\n",
    "**Vector Data** - Rank 2 tensor of the shape (Sample, Features). \\\n",
    "**Timeseries data or Sequence data** - Rank 3 tensor of the shape (samples, timesteps, features). \\\n",
    "**Images** - Rank 4 tensors of shape (samples, height, width, channels). \\\n",
    "**Video** - Rank 5 tensor of shape (samples, frames, height, width, channels). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector Data Example**\\\n",
    "The data of gender and age of 10,000 people can be stores in a tensor of the shape (10000, 2) where 10,000 arrays of two values are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timeseries Data or Sequence Data Example** \\\n",
    "Recording stock price of a stock is an example. The highest and the lowest price of the minute is recorded in each minute. There are 390 active stock minutes and 250 active stock days. Therefore a tensor of the shape (250,390,2) can be used to store this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Data** \\\n",
    "To store 128 images with 256 x 256 pixels and the RGB representation, we can use a rank 4 tensor of the shape (128,256,256,3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Video Data** \\\n",
    "A video is a sequence of frames. A YouTube video which have 60 seconds and 144x256 resolution and 4 frames per second can be stores in a rank 5 tensor. So 4 such videos can be stored in a tensor which has the shape of (4, 240, 144, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Operations** \\\n",
    "All transformations learned by deep neural network can be reduced to tensor operations.\\\n",
    "\n",
    "*Element-wise operations* \\\n",
    "operations that are applied independently to each entry in the tensors being considered. Dot operation and element-wise addition can be considered as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 100)\n",
      "(20, 100)\n",
      "[[1.01555762 0.73690458 0.51387166 ... 1.18858553 1.04847309 1.20867557]\n",
      " [1.1338832  0.9442322  0.34078703 ... 0.84699975 0.44849796 0.99036479]\n",
      " [1.14758528 0.5503791  1.21364131 ... 0.92528599 1.03839236 0.88844451]\n",
      " ...\n",
      " [1.45416179 0.78196594 1.28614945 ... 0.87333899 1.07420109 0.43337333]\n",
      " [1.0228646  1.17655137 1.53688811 ... 1.14517991 1.19250443 1.4806409 ]\n",
      " [1.60441231 1.18441738 0.87166395 ... 1.16091929 1.35519129 1.87619353]]\n",
      "[[1.01555762 0.73690458 0.51387166 ... 1.18858553 1.04847309 1.20867557]\n",
      " [1.1338832  0.9442322  0.34078703 ... 0.84699975 0.44849796 0.99036479]\n",
      " [1.14758528 0.5503791  1.21364131 ... 0.92528599 1.03839236 0.88844451]\n",
      " ...\n",
      " [1.45416179 0.78196594 1.28614945 ... 0.87333899 1.07420109 0.43337333]\n",
      " [1.0228646  1.17655137 1.53688811 ... 1.14517991 1.19250443 1.4806409 ]\n",
      " [1.60441231 1.18441738 0.87166395 ... 1.16091929 1.35519129 1.87619353]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "z = x + y #Element-wise addition\n",
    "print(z)\n",
    "z = np.maximum(z, 0.) #Element-wise ReLU\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcasting** \\\n",
    "Broadcasting is the process of matching two vectors to be in the same shape when a elementwise operation is performed. This process consists of two steps:\n",
    " - Axes are added to the smaller tensor to match the larger tensors shape.\n",
    " - The smaller tensor is then repeated alongside these axes to match the full shape. \n",
    "\n",
    "The repetition operation is entirely virtual: it happens at the algorithmic level rather than at the memory level. But thinking of the vector being repeated 10 times alongside a new axis is a helpful mental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      " 0.19150778 0.4286204  0.58008238 0.94428811]\n",
      "\n",
      "(1, 10)\n",
      "[[0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]]\n",
      "\n",
      "(32, 10)\n",
      "[[0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]\n",
      " [0.81442217 0.64900676 0.43480117 0.96927029 0.65364736 0.26079234\n",
      "  0.19150778 0.4286204  0.58008238 0.94428811]]\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((32,10))\n",
    "y = np.random.random((10,))\n",
    "y1 = y.copy()\n",
    "print(y.shape)\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "y = np.expand_dims(y, axis=0)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "y = np.concatenate([y]*32, axis=0)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "print(np.array_equal(np.maximum(x, y), np.maximum(x, y1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor product or Dot product**\\\n",
    "You can take the dot product of two matrices x and y (dot(x, y)) if and only if x.shape[1]==y.shape[0]. The result is a matrix with shape (x.shape[0], y shape[1]), where the coefficients are the vector products between the rows of x and the columns of y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2) (2, 2) (2, 2)\n",
      "[[19 22]\n",
      " [43 50]]\n",
      "\n",
      "[[19. 22.]\n",
      " [43. 50.]]\n"
     ]
    }
   ],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1 \n",
    "    assert len(y.shape) == 1 \n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z\n",
    "\n",
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2 \n",
    "    assert len(y.shape) == 2 \n",
    "    assert x.shape[1] == y.shape[0] \n",
    "    z = np.zeros((x.shape[0], y.shape[1])) \n",
    "    for i in range(x.shape[0]): \n",
    "        for j in range(y.shape[1]): \n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z\n",
    "\n",
    "import numpy as np\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "y = np.array([[5, 6], [7, 8]])\n",
    "z = np.dot(x, y)\n",
    "print(x.shape,y.shape,z.shape)\n",
    "print(z)\n",
    "print()\n",
    "\n",
    "z = naive_matrix_dot(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Reshaping**\\\n",
    "Reshaping a tensor means rearranging its rows and columns to match a target shape.  Transposing a matrix means exchanging its rows and its columns, so that x[i, :] becomes x[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3)\n",
      "(192, 1)\n",
      "(1, 192)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((64, 3))\n",
    "print(x.shape)\n",
    "x = x.reshape(64*3, 1)\n",
    "print(x.shape)\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradian Tape in tensorflow** \\\n",
    "It’s a Python scope that will “record” the tensor operations that run inside it, in the form of a computation graph. This graph can then be used to retrieve the gradient of any output with respect to any variable or set of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(10.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_with_respect_to_x = tape.gradient(y, x)\n",
    "print(grad_of_y_with_respect_to_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    " layers.Dense(512, activation=\"relu\"),\n",
    " layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    " loss=\"sparse_categorical_crossentropy\",\n",
    " metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 7s 7ms/step - loss: 0.2571 - accuracy: 0.9268\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1046 - accuracy: 0.9692\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0685 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0502 - accuracy: 0.9850\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.0376 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238a0197910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "print(predicted_labels[:10])\n",
    "print(test_labels[:10])\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
